{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSyzkMZipHFk",
    "outputId": "97ece3df-3f65-4d54-e9e7-5a3a889e72dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 3\n",
      "Thank you all for ther incredible collectively felt is reat we need this. First to all so very much. The Revenant want cing out man's reating. We need to all so verybody at was thern this people castly, for this. First urgence. And thout ther increen … the Reverybody at For this that facinemate congratural world billion scredible childrent talentireless efforts of grant we natics of you know who you in 2015 as and creen … To my can und for thank your procrastly, I love you deavor, Mr. Thank you to world. And credible nees have the to the Academy. To most who you so verybody at Fox and for chank everyone from Hardy. Our take to thank your chank evenanted togethe to speak forts of threat was and for our crew. Climating right. Let urgentire to be support leademy. Our frience. Thange in the most and ther … my cast of this yearly; you know who do not to most and lastination screen drowned to support leaders, I the veryone friendent this. Fox an on scredible needed out wanted. Tom, you for thank you increed. I have billionship to colluters, and New Revery much. To most only brothe productions able world, fort leademy. The species, and New Reverybody at for grant to thout to my pareen … my friends, but manity, for an unbelievable of my brother in reat we can onset of my friency … my felt is room. I do nomineed his. First us planet us people who you to would to would big politics of you to findigenous people this reless effor children, and snow. I love you tonight. Let of the whose voices have ther … my pare. Thank your ents; not speak for our crew. It ind to the of gratulate this. For the billionship to world to all for ther and lasting awardy. Our child\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "paragraph = \"\"\"Thank you all so very much. Thank you to the Academy. Thank you to all of you in this room. I have to congratulate the other incredible nominees this year. The Revenant was the product of the tireless efforts of an unbelievable cast and crew. First off, to my brother in this endeavor, Mr. Tom Hardy. Tom, your talent on screen can only be surpassed by your friendship off screen … thank you for creating a transcendent cinematic experience. Thank you to everybody at Fox and New Regency … my entire team. I have to thank everyone from the very onset of my career … To my parents; none of this would be possible without you. And to my friends, I love you dearly; you know who you are. And lastly, I just want to say this: Making The Revenant was about man's relationship to the natural world. A world that we collectively felt in 2015 as the hottest year in recorded history. Our production needed to move to the southern tip of this planet just to be able to find snow. Climate change is real, it is happening right now. It is the most urgent threat facing our entire species, and we need to work collectively together and stop procrastinating. We need to support leaders around the world who do not speak for the big polluters, but who speak for all of humanity, for the indigenous people of the world, for the billions and billions of underprivileged people out there who would be most affected by this. For our children’s children, and for those people out there whose voices have been drowned out by the politics of greed. I thank you all for this amazing award tonight. Let us not take this planet for granted. I do not take tonight for granted. Thank you so very much.\"\"\"\n",
    "words = paragraph.split()\n",
    "\n",
    "def create_ngram_letters(n):\n",
    "\tn_gram = {}\n",
    "\tfor i in range(len(paragraph) - n):\n",
    "\t    if paragraph[i:i+n] not in n_gram.keys():\n",
    "\t        n_gram[paragraph[i:i+n]] = [paragraph[i+n]]\n",
    "\t    else:\n",
    "\t        n_gram[paragraph[i:i+n]].append(paragraph[i+n])\n",
    "\treturn n_gram\n",
    "\n",
    "def auto_complete_letters(n, n_gram, init = []):\n",
    "\tif len(init) < n:\n",
    "\t\tinit = list(paragraph[:n])\n",
    "\tfor i in range(n, len(paragraph)):\n",
    "\t    current_gram = ''.join(init[i-n:i])\n",
    "\t    if current_gram not in n_gram:\n",
    "\t        break\n",
    "\t    init.append(n_gram[current_gram][random.randrange(len(n_gram[current_gram]))])\n",
    "\treturn(''.join(init))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tn = int(input(\"n: \"))\n",
    "\tn_gram_letters = create_ngram_letters(n)\n",
    "\tprint(auto_complete_letters(n, n_gram_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fye1YzOkpOxk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
